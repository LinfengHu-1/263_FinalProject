---
title: "SVM & Logistic Regression"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(dplyr)
library(class)
```

```{r}
library(dplyr)
dat <- read.csv('brfss_final.csv')
outcome <- data.frame(dat$X,dat$MICHD,dat$CVDINFR4,dat$CVDCRHD4)
outcome %>% group_by(dat.MICHD) %>% summarise(count=n())
outcome %>% group_by(dat.CVDINFR4) %>% summarise(count=n())
outcome %>% group_by(dat.CVDCRHD4) %>% summarise(count=n())

## remove the ones that responded don't know & not sure in CVDINFR4 & CVDCRHD4
dat <- dat[-which(dat$CVDINFR4 == 7 | dat$CVDINFR4 == 9),] 
dat <- dat[-which(dat$CVDCRHD4 == 7 | dat$CVDCRHD4 == 9),] 

# remove columns that has only 1 value for all rows
dat <- dat[ , -which(names(dat) %in% c("MEDSHEPB","TOLDCFS", "HAVECFS", "WORKCFS"))]
```

### Drop columns with more than 5% data missing, impute the rest using KNN
```{r}
# convert outcome variables
dat$MICHD <- factor(2-dat$MICHD)
dat$CVDINFR4 <- factor(2-dat$CVDINFR4)
dat$CVDCRHD4 <- factor(2-dat$CVDCRHD4)

# i believe X is the index column, not needed
# remove weights
dat <- dat[, !colnames(dat) %in% c('X', 'LLCPWT2', 'LLCPWT', 'CLLCPWT','STRWT','WT2RAKE')]
threshold <- .05
ncol(dat) # 190

dat <- dat[, colMeans(is.na(dat)) <= threshold]
ncol(dat) # 52 columns left

columns_to_impute <- colnames(dat)[colSums(is.na(dat)) > 0]
columns_to_impute
str(dat[,columns_to_impute])

complete_columns <- colnames(dat)[colSums(is.na(dat)) == 0 & 
                                      !colnames(dat) %in% c('MICHD', 'CVDINFR4','CVDCRHD4')]

for (c in columns_to_impute) {
    col <- dat[[c]]
    scaled <- scale(dat[, complete_columns])
    knn <- knn(
        train = scaled[!is.na(col), complete_columns],
        test  = scaled[is.na(col), complete_columns], 
        cl    = dat[!is.na(col), c]
        )
    
    dat[is.na(col), c] = knn
}

colSums(is.na(dat))
```

```{r}
library(e1071)
library(caret)
library(ROCR)
set.seed(263)
train_index <- createDataPartition(dat$MICHD, p = 0.8, list = FALSE)
train <- dat[train_index, ]
test <- dat[-train_index, ]
```



## Linfeng - Plain Logistic Regression
```{r}
# Create factor variables for outcomes
# train$MICHD <- factor(ifelse(train$MICHD == 2, "no", "yes"))
# train$CVDINFR4 <- factor(ifelse(train$CVDINFR4 == 2, "no", "yes"))
# train$CVDCRHD4 <- factor(ifelse(train$CVDCRHD4 == 2, "no", "yes"))
# test$MICHD <- factor(ifelse(test$MICHD == 2, "no", "yes"))
# test$CVDINFR4 <- factor(ifelse(test$CVDINFR4 == 2, "no", "yes"))
# test$CVDCRHD4 <- factor(ifelse(test$CVDCRHD4 == 2, "no", "yes"))

#sapply(lapply(dat, unique), length)
mylogit <- glm(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train, na.action = na.omit, 
               family = "binomial")
#summary(mylogit)
library(caret)
ctrlspecs <- trainControl(method="cv", number=10, savePredictions="all", classProbs=TRUE)
logit_cv <- train(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train, method="glm", family=binomial, 
                  trControl=ctrlspecs)

library(boot)
cv_results <- cv.glm(data = train, glmfit = mylogit, K = 2)
best_fold <- which.min(cv_results$cvm)
best_acc <- cv_results$delta[best_fold]
best_sen <- cv_results$delta[best_fold, "Sensitivity"]
best_spe <- cv_results$delta[best_fold, "Specificity"]

################################## Ridge Regression ############################
# set up grid of lambda values to try
lambda_grid <- 10^seq(-4, 4, by = 1)
# perform cross-validation to tune lambda
cv_results <- cv.glmnet(x = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train),
                        y = train$MICHD,
                        alpha = 0,  # L2 penalty (ridge regression)
                        family = "binomial",
                        type.measure = "class",  # use classification accuracy as evaluation metric
                        lambda = lambda_grid)
# select lambda that yields best classification accuracy
best_lambda <- cv_results$lambda.min
# train model on full training set with selected lambda
mylogit <- glmnet(x = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train),
                  y = train$MICHD,
                  alpha = 0,  # L2 penalty (ridge regression)
                  family = "binomial",
                  lambda = best_lambda)
# evaluate model performance on test set
pred <- predict(mylogit, newx = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = test))
pred_class <- ifelse(pred > 0, 1, 0)
accuracy <- mean(pred_class == test$MICHD)
sensitivity <- sum(pred_class[test$MICHD == 1] == 1) / sum(test$MICHD == 1)
specificity <- sum(pred_class[test$MICHD == 0] == 0) / sum(test$MICHD == 0)
cat(paste("Best lambda:", best_lambda, "\n"))
cat(paste("Accuracy:", accuracy, "\n"))
cat(paste("Sensitivity:", sensitivity, "\n"))
cat(paste("Specificity:", specificity, "\n"))
```

## Ridge & Lasso for Feature Selection

```{r}
x <- model.matrix(MICHD~., data=train)
y <- train$MICHD
grid <- seq(0, .8, length=100)
cv_lasso <- cv.glmnet(x, as.numeric(y), alpha=1, lambda=grid, penalty.factor = c(rep(1,18), rep(0,ncol(x)-18)))

print(cv_lasso)
plot(cv_lasso)
```


## Linfeng - SVM
```{r}

dat <- dat %>% mutate_if(is.character, as.numeric)
dat <- dat %>% mutate_if(is.factor, as.numeric)
dat <- dat %>% mutate_if(is.logical, as.numeric)

# Fit SVM models for each outcome
model_MICHD <- svm(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train, na.action =na.omit, 
                   type = "C-classification",kernel = "linear", cost = 1)
model_CVDINFR4 <- svm(CVDINFR4 ~ .- MICHD - CVDCRHD4, data = train, 
                      type = "C-classification", kernel = "linear")
model_CVDCRHD4 <- svm(CVDCRHD4 ~ .- MICHD - CVDINFR4, data = train, 
                      type = "C-classification", kernel = "linear")

# Predict on testing set for each outcome
pred_MICHD <- predict(model_MICHD, newdata = test)
pred_CVDINFR4 <- predict(model_CVDINFR4, newdata = test)
pred_CVDCRHD4 <- predict(model_CVDCRHD4, newdata = test)

# Evaluate accuracy for each outcome
confusionMatrix(pred_MICHD, test$MICHD)
confusionMatrix(pred_CVDINFR4, test$CVDINFR4)
confusionMatrix(pred_CVDCRHD4, test$CVDCRHD4)

# Plot ROC curves for each outcome
pred_MICHD_prob <- predict(model_MICHD, newdata = test, probability = TRUE)
pred_CVDINFR4_prob <- predict(model_CVDINFR4, newdata = test, probability = TRUE)
pred_CVDCRHD4_prob <- predict(model_CVDCRHD4, newdata = test, probability = TRUE)

pred_MICHD_roc <- prediction(attr(pred_MICHD_prob,"probabilities")[,"yes"], test$MICHD)
pred_CVDINFR4_roc <- prediction(attr(pred_CVDINFR4_prob,"probabilities")[,"yes"], test$CVDINFR4)
pred_CVDCRHD4_roc <- prediction(attr(pred_CVDCRHD4_prob,"probabilities")[,"yes"], test$CVDCRHD4)
```

