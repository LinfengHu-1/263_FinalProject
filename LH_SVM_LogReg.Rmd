---
title: "SVM & Logistic Regression"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(dplyr)
library(class)
```

```{r}
library(dplyr)
dat <- read.csv('brfss_final.csv')
outcome <- data.frame(dat$X,dat$MICHD,dat$CVDINFR4,dat$CVDCRHD4)
outcome %>% group_by(dat.MICHD) %>% summarise(count=n())
outcome %>% group_by(dat.CVDINFR4) %>% summarise(count=n())
outcome %>% group_by(dat.CVDCRHD4) %>% summarise(count=n())

## remove the ones that responded don't know & not sure in CVDINFR4 & CVDCRHD4
dat <- dat[-which(dat$CVDINFR4 == 7 | dat$CVDINFR4 == 9),] 
dat <- dat[-which(dat$CVDCRHD4 == 7 | dat$CVDCRHD4 == 9),] 

# remove columns that has only 1 value for all rows
dat <- dat[ , -which(names(dat) %in% c("MEDSHEPB","TOLDCFS", "HAVECFS", "WORKCFS"))]
```

### Drop columns with more than 5% data missing, impute the rest using KNN
```{r}
# convert outcome variables
dat$MICHD <- factor(2-dat$MICHD)
dat$CVDINFR4 <- factor(2-dat$CVDINFR4)
dat$CVDCRHD4 <- factor(2-dat$CVDCRHD4)

# i believe X is the index column, not needed
# remove weights
dat <- dat[, !colnames(dat) %in% c('X', 'LLCPWT2', 'LLCPWT', 'CLLCPWT','STRWT','WT2RAKE')]
dat <- dat[, !colnames(dat) %in% c('QSTVER', 'STSTR','RAWRAKE')] # remove based on knowledge
threshold <- .05
ncol(dat) # 190

dat <- dat[, colMeans(is.na(dat)) <= threshold]
ncol(dat) # 52 columns left

columns_to_impute <- colnames(dat)[colSums(is.na(dat)) > 0]
#columns_to_impute
str(dat[,columns_to_impute])

complete_columns <- colnames(dat)[colSums(is.na(dat)) == 0 & 
                                      !colnames(dat) %in% c('MICHD', 'CVDINFR4','CVDCRHD4')]

for (c in columns_to_impute) {
    col <- dat[[c]]
    scaled <- scale(dat[, complete_columns])
    knn <- knn(
        train = scaled[!is.na(col), complete_columns],
        test  = scaled[is.na(col), complete_columns], 
        cl    = dat[!is.na(col), c]
        )
    
    dat[is.na(col), c] = knn
}

colSums(is.na(dat))
```

### PCA

```{r}
dat <- dat[, !(colnames(dat) %in% c("CVDINFR4","CVDCRHD4"))]


dat_pc <- apply(dat, 2, as.numeric)
pca <- prcomp(dat_pc, scale. = TRUE)  
#summary(pca)
pca_data <- predict(pca, newdata = dat_pc)[, 1:30]  

# new data frame with top 30 PCs & the outcome variable
pca_dat <- data.frame(pca_data, MICHD = dat$MICHD)

set.seed(263)
train_index <- createDataPartition(dat$MICHD, p = 0.8, list = FALSE)
train_pc <- pca_dat[train_index, ]
test_pc <- pca_dat[-train_index, ]

#logit_model <- glm(MICHD ~ ., data = pca_dat, family = binomial(link = "logit"))
train_pc$MICHD <- make.names(train_pc$MICHD)
ctrl <- trainControl(method = "cv",number = 10,classProbs = TRUE,
                     summaryFunction = twoClassSummary, savePredictions = TRUE)
fit_michd <- train(MICHD ~ ., data = train_pc, method = "glm", 
                   family = "binomial", trControl = ctrl, metric = "ROC")
result_MICHD <- data.frame(fit_michd$results)
result_MICHD <- result_MICHD[,2:4]
result_MICHD <- cbind(Model = "Plain Logistic Regression", Outcome = "MICHD", result_MICHD)
result_MICHD


test_pc$MICHD <- make.names(test_pc$MICHD)
log_pred <- predict(fit_michd, newdata = test_pc)
cm <- confusionMatrix(data = log_pred, reference = factor(test_pc$MICHD))
cm

# Extract the prediction values as numeric
log_pred <- as.numeric(predict(fit_michd, newdata = test_pc))
roc_data <- data.frame(actual = test_pc$MICHD, predicted = log_pred)
library(pROC)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
```


### Start modeling

```{r}
library(e1071)
library(caret)
library(ROCR)
set.seed(263)
train_index <- createDataPartition(dat$MICHD, p = 0.8, list = FALSE)
train <- dat[train_index, ]
test <- dat[-train_index, ]
```



## Linfeng - Plain Logistic Regression
```{r}
train$MICHD <- make.names(train$MICHD)
#train$CVDCRHD4 <- make.names(train$CVDCRHD4)
#train$CVDINFR4 <- make.names(train$CVDINFR4)
test$MICHD <- make.names(test$MICHD)
#test$CVDCRHD4 <- make.names(test$CVDCRHD4)
#test$CVDINFR4 <- make.names(test$CVDINFR4)
#mylogit <- glm(MICHD ~ .- CVDINFR4 - CVDCRHD4,data=train, na.action = na.omit, family="binomial")
library(caret)
ctrl <- trainControl(method = "cv",number = 10,classProbs = TRUE,
                     summaryFunction = twoClassSummary, savePredictions = TRUE)
fit_michd <- train(MICHD ~ ., data = train, method = "glm", 
                   family = "binomial", trControl = ctrl, metric = "Accuracy")
result_MICHD <- data.frame(fit_michd$results)
result_MICHD <- result_MICHD[,2:4]
result_MICHD <- cbind(Model = "Plain Logistic Regression", Outcome = "MICHD", result_MICHD)
# fit_mi <- train(CVDINFR4 ~ .- MICHD - CVDCRHD4, data = train, method = "glm", 
#                    family = "binomial", trControl = ctrl, metric = "ROC")
# result_MI <- data.frame(fit_mi$results)
# result_MI <- result_MI[,2:4]
# result_MI <- cbind(Model = "Plain Logistic Regression", Outcome = "MI", result_MI)
# fit_chd <- train(CVDCRHD4 ~ .- CVDINFR4 - MICHD, data = train, method = "glm", 
#                    family = "binomial", trControl = ctrl, metric = "ROC")
# result_CHD <- data.frame(fit_chd$results)
# result_CHD <- result_CHD[,2:4]
# result_CHD <- cbind(Model = "Plain Logistic Regression", Outcome = "CHD", result_CHD)
# 
# result_log <- rbind(result_MI, result_CHD, result_MICHD)
# result_log

log_pred <- predict(fit_michd, newdata = test)
cm <- confusionMatrix(data = log_pred, reference = factor(test$MICHD))
cm

# Extract the prediction values as numeric
log_pred <- as.numeric(predict(fit_michd, newdata = test))
roc_data <- data.frame(actual = test$MICHD, predicted = log_pred)
library(pROC)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
```



## Ridge & Lasso for Feature Selection

```{r}
x <- model.matrix(MICHD~., data=train)
y <- train$MICHD
grid <- seq(0, .8, length=100)
cv_lasso <- cv.glmnet(x, as.numeric(y), alpha=1, lambda=grid, penalty.factor = c(rep(1,18), rep(0,ncol(x)-18)))

print(cv_lasso)
plot(cv_lasso)
```


## Linfeng - SVM

## SVM with PCA
```{r}
ctrl <- trainControl(method = "cv", number = 3, summaryFunction = twoClassSummary, 
                     classProbs = TRUE, verboseIter = TRUE)
tuneGrid <- expand.grid(C = c(0.1, 1, 10), sigma = c(0.1, 1, 10))
svm_model <- train(MICHD ~ ., data = train_pc, method = "svmRadial", trControl = ctrl, tuneGrid = tuneGrid, metric = "ROC")
#sigma = 0.1, C = 10
svmlin_pred <- predict(svm_model, newdata = test_pc)
cm <- confusionMatrix(data = svmlin_pred, reference = factor(test_pc$MICHD))
cm
svmlin_pred <- as.numeric(predict(svm_model, newdata = test_pc))
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svmlin_pred)
library(pROC)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
############################ Linear ############################
SVMlinearGrid <- expand.grid(C = c(0.1, 0.7, 1, 10))
svm_linear <- train(MICHD ~ ., data = train_pc, method = "svmLinear", trControl = ctrl, tuneGrid = SVMlinearGrid, metric = "ROC")
result_linear_MICHD <- data.frame(svm_linear$results)
result_linear_MICHD <- result_linear_MICHD[,1:4]
result_linear_MICHD <- cbind(Model = "SVM - Linear", Outcome = "MICHD", result_linear_MICHD)
result_linear_MICHD
svm_linear$bestTune #  C = 0.7
svm_pred <- predict(svm_linear, newdata = test_pc)
cm <- confusionMatrix(data = svm_pred, reference = factor(test_pc$MICHD))
cm
svm_pred <- as.numeric(svm_pred)
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svm_pred)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
############################ Polynomial ############################
svm_poly <- train(MICHD ~ ., data = train_pc, method = "svmPoly", trControl = ctrl, tuneLength = 3, preProcess = c("center","scale"),metric = "ROC")
result_poly_MICHD <- data.frame(svm_poly$results)
result_poly_MICHD <- result_poly_MICHD[,1:6]
result_poly_MICHD <- cbind(Model = "SVM - Polynomial", Outcome = "MICHD", result_poly_MICHD)
result_poly_MICHD
svm_poly$bestTune # degree = 3, scale = 0.01, C = 1
# Predict on test dataset
# Construct the SVM with the best hyperparameters
svm_poly <- svm(as.numeric(factor(train_pc$MICHD)) ~ ., data = train_pc, kernel = "polynomial", 
                degree = 3, gamma = 1/0.01, cost = 1)
predictions <- predict(svm_poly, test_pc)


# Predict using the SVM on the test data
predictions = svm_poly.predict(test_pc)
svm_pred <- predict(svm_poly, newdata = test_pc)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD_pc))
cm
svm_pred <- as.numeric(svm_pred)
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svm_pred)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
```



## plain SVM
```{r}
ctrl <- trainControl(method = "cv", number = 3, summaryFunction = twoClassSummary, 
                     classProbs = TRUE, verboseIter = TRUE)
tuneGrid <- expand.grid(C = c(0.1, 1, 10), sigma = c(0.1, 1, 10))
svm_model <- train(MICHD ~ ., data = train, method = "svmRadial", trControl = ctrl, tuneGrid = tuneGrid, metric = "ROC")
result_MICHD <- data.frame(svm_model$results)
result_MICHD <- result_MICHD[,1:5]
result_MICHD <- cbind(Model = "SVM - Radial", Outcome = "MICHD", result_MICHD)
result_MICHD
svm_model$bestTune # C = 1, sigma = 0.1
# get Confusion Matrix
train$MICHD <- as.factor(train$MICHD)
svm_model <- svm(MICHD ~ ., data = train, cost = 1, sigma = 0.1,kernel = "radial")
# Make predictions on the test set
svm_pred <- predict(svm_model, newdata = test)
accuracy <- sum(svm_pred == test$MICHD) / nrow(test)

# Linear Kernel
SVMlinearGrid <- expand.grid(C = c(0.1, 0.7, 1, 10))
svm_linear <- train(MICHD ~ ., data = train, method = "svmLinear", trControl = ctrl, tuneGrid = SVMlinearGrid, metric = "ROC")
result_linear_MICHD <- data.frame(svm_linear$results)
result_linear_MICHD <- result_linear_MICHD[,1:4]
result_linear_MICHD <- cbind(Model = "SVM - Linear", Outcome = "MICHD", result_linear_MICHD)
result_linear_MICHD
svm_linear$bestTune
svm_pred <- predict(svm_linear, newdata = test)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD))
cm
library(pROC)
svm_pred <- predict(svm_linear, newdata = test, type = "prob")
svm_auc <- roc(factor(test$MICHD), svm_pred[,"X1"])$auc
svm_auc


# Fit the model 
svm_poly <- train(MICHD ~ .-CVDINFR4-CVDCRHD4, data = train, method = "svmPoly", trControl = ctrl, tuneLength = 3, preProcess = c("center","scale"),metric = "ROC")
result_poly_MICHD <- data.frame(svm_poly$results)
result_poly_MICHD <- result_poly_MICHD[,1:6]
result_poly_MICHD <- cbind(Model = "SVM - Polynomial", Outcome = "MICHD", result_poly_MICHD)
result_poly_MICHD
svm_poly$bestTune # degree = 2, scale = 0.01, C = 0.25
# Predict on test dataset
svm_pred <- predict(svm_poly, newdata = test)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD))
cm
library(pROC)
svm_pred <- predict(svm_poly, newdata = test, type = "prob")
svm_auc <- roc(factor(test$MICHD), svm_pred[,"X1"])$auc
svm_auc
```


```{r}
# Create factor variables for outcomes
# train$MICHD <- factor(ifelse(train$MICHD == 2, "no", "yes"))
# train$CVDINFR4 <- factor(ifelse(train$CVDINFR4 == 2, "no", "yes"))
# train$CVDCRHD4 <- factor(ifelse(train$CVDCRHD4 == 2, "no", "yes"))
# test$MICHD <- factor(ifelse(test$MICHD == 2, "no", "yes"))
# test$CVDINFR4 <- factor(ifelse(test$CVDINFR4 == 2, "no", "yes"))
# test$CVDCRHD4 <- factor(ifelse(test$CVDCRHD4 == 2, "no", "yes"))
```

```{r}
################################## Ridge Regression ############################
# set up grid of lambda values to try
lambda_grid <- 10^seq(-4, 4, by = 1)
# perform cross-validation to tune lambda
cv_results <- cv.glmnet(x = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train),
                        y = train$MICHD,
                        alpha = 0,  # L2 penalty (ridge regression)
                        family = "binomial",
                        type.measure = "class",  # use classification accuracy as evaluation metric
                        lambda = lambda_grid)
# select lambda that yields best classification accuracy
best_lambda <- cv_results$lambda.min
# train model on full training set with selected lambda
mylogit <- glmnet(x = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = train),
                  y = train$MICHD,
                  alpha = 0,  # L2 penalty (ridge regression)
                  family = "binomial",
                  lambda = best_lambda)
# evaluate model performance on test set
pred <- predict(mylogit, newx = model.matrix(MICHD ~ .- CVDINFR4 - CVDCRHD4, data = test))
pred_class <- ifelse(pred > 0, 1, 0)
accuracy <- mean(pred_class == test$MICHD)
sensitivity <- sum(pred_class[test$MICHD == 1] == 1) / sum(test$MICHD == 1)
specificity <- sum(pred_class[test$MICHD == 0] == 0) / sum(test$MICHD == 0)
```
