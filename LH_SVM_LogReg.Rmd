---
title: "SVM & Logistic Regression"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(dplyr)
library(class)
```

```{r}
library(dplyr)
dat <- read.csv('brfss_final.csv')
outcome <- data.frame(dat$X,dat$MICHD,dat$CVDINFR4,dat$CVDCRHD4)
outcome %>% group_by(dat.MICHD) %>% summarise(count=n())
outcome %>% group_by(dat.CVDINFR4) %>% summarise(count=n())
outcome %>% group_by(dat.CVDCRHD4) %>% summarise(count=n())

## remove the ones that responded don't know & not sure in CVDINFR4 & CVDCRHD4
dat <- dat[-which(dat$CVDINFR4 == 7 | dat$CVDINFR4 == 9),] 
dat <- dat[-which(dat$CVDCRHD4 == 7 | dat$CVDCRHD4 == 9),] 

# remove columns that has only 1 value for all rows
dat <- dat[ , -which(names(dat) %in% c("MEDSHEPB","TOLDCFS", "HAVECFS", "WORKCFS"))]
```

### Drop columns with more than 5% data missing, impute the rest using KNN
```{r}
# convert outcome variables
dat$MICHD <- factor(2-dat$MICHD)
dat$CVDINFR4 <- factor(2-dat$CVDINFR4)
dat$CVDCRHD4 <- factor(2-dat$CVDCRHD4)
# remove weights
dat <- dat[, !colnames(dat) %in% c('X', 'LLCPWT2', 'LLCPWT', 'CLLCPWT','STRWT','WT2RAKE')]
dat <- dat[, !colnames(dat) %in% c('QSTVER', 'STSTR','RAWRAKE')] # remove based on knowledge
threshold <- .05 # now dat has 190 columns
dat <- dat[, colMeans(is.na(dat)) <= threshold] # 52 columns left

columns_to_impute <- colnames(dat)[colSums(is.na(dat)) > 0]
str(dat[,columns_to_impute])
complete_columns <- colnames(dat)[colSums(is.na(dat)) == 0 & 
                                      !colnames(dat) %in% c('MICHD', 'CVDINFR4','CVDCRHD4')]
for (c in columns_to_impute) {
    col <- dat[[c]]
    scaled <- scale(dat[, complete_columns])
    knn <- knn(
        train = scaled[!is.na(col), complete_columns],
        test  = scaled[is.na(col), complete_columns], 
        cl    = dat[!is.na(col), c]
        )
    
    dat[is.na(col), c] = knn
}

colSums(is.na(dat))
```


### Start modeling

```{r}
library(e1071)
library(caret)
library(ROCR)
library(pROC)
set.seed(263)
dat <- dat[, !(colnames(dat) %in% c("CVDINFR4","CVDCRHD4"))]
train_index <- createDataPartition(dat$MICHD, p = 0.8, list = FALSE)
train <- dat[train_index, ]
test <- dat[-train_index, ]
```


### PCA

```{r}
train_data <- train[, !(colnames(train) %in% c("MICHD"))]
test_data <- test[, !(colnames(test) %in% c("MICHD"))]

train_pc <- apply(train_data, 2, as.numeric)
pca <- prcomp(train_pc, scale. = TRUE)  
pca_data <- predict(pca, newdata = train_pc)[, 1:30]  
train_pc <- data.frame(pca_data, MICHD = train$MICHD)
test_pc <- apply(test_data, 2, as.numeric)
pca <- prcomp(test_pc, scale. = TRUE)  
pca_data <- predict(pca, newdata = test_pc)[, 1:30]  
test_pc <- data.frame(pca_data, MICHD = test$MICHD)

train_pc$MICHD <- make.names(train_pc$MICHD)
test_pc$MICHD <- make.names(test_pc$MICHD)
```

PCA - Logistic Regression
```{r}
ctrl <- trainControl(method = "cv",number = 10,classProbs = TRUE,
                     summaryFunction = twoClassSummary, savePredictions = TRUE)
fit_michd <- train(MICHD ~ ., data = train_pc, method = "glm", 
                   family = "binomial", trControl = ctrl, metric = "ROC")
result_MICHD <- data.frame(fit_michd$results)
result_MICHD <- result_MICHD[,2:4]
result_MICHD <- cbind(Model = "Plain Logistic Regression", Outcome = "MICHD", result_MICHD)
result_MICHD

log_pred <- predict(fit_michd, newdata = test_pc)
cm <- confusionMatrix(data = log_pred, reference = factor(test_pc$MICHD))
cm

# Extract the prediction values as numeric
log_pred <- as.numeric(predict(fit_michd, newdata = test_pc))
roc_data <- data.frame(actual = test_pc$MICHD, predicted = log_pred)
roc_log_pc <- roc(roc_data$actual, roc_data$predicted)
#ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
#  geom_line(aes(x = x, y = y)) +
#  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
#  labs(title = "Receiver Operating Characteristic (ROC) Curve",
#       x = "False Positive Rate (1 - Specificity)",
#       y = "True Positive Rate (Sensitivity)")
```






## Linfeng - Plain Logistic Regression
```{r}
train$MICHD <- make.names(train$MICHD)
test$MICHD <- make.names(test$MICHD)
library(caret)
ctrl <- trainControl(method = "cv",number = 10,classProbs = TRUE,
                     summaryFunction = twoClassSummary, savePredictions = TRUE)
fit_michd <- train(MICHD ~ ., data = train, method = "glm", 
                   family = "binomial", trControl = ctrl, metric = "ROC")
result_MICHD <- data.frame(fit_michd$results)
result_MICHD <- result_MICHD[,2:4]
result_MICHD <- cbind(Model = "Plain Logistic Regression", Outcome = "MICHD", result_MICHD)
log_pred <- predict(fit_michd, newdata = test)
cm <- confusionMatrix(data = log_pred, reference = factor(test$MICHD))
cm
log_pred <- as.numeric(predict(fit_michd, newdata = test))
roc_data <- data.frame(actual = test$MICHD, predicted = log_pred)
library(pROC)
roc_log_normal <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
```



## Ridge & Lasso for Feature Selection

```{r}
x <- model.matrix(MICHD~., data=train)
y <- train$MICHD
grid <- seq(0, .8, length=100)
cv_lasso <- cv.glmnet(x, as.numeric(y), alpha=1, lambda=grid, penalty.factor = c(rep(1,18), rep(0,ncol(x)-18)))

print(cv_lasso)
plot(cv_lasso)
```


## Linfeng - SVM

## plain SVM
```{r}
ctrl <- trainControl(method = "cv", number = 3, summaryFunction = twoClassSummary, 
                     classProbs = TRUE, verboseIter = TRUE)
tuneGrid <- expand.grid(C = c(0.1, 1, 10), sigma = c(0.1, 1, 10))
svm_model <- train(MICHD ~ ., data = train, method = "svmRadial", trControl = ctrl, tuneGrid = tuneGrid, metric = "ROC")
result_MICHD <- data.frame(svm_model$results)
result_MICHD <- result_MICHD[,1:5]
result_MICHD <- cbind(Model = "SVM - Radial", Outcome = "MICHD", result_MICHD)
result_MICHD
svm_model$bestTune # C = 1, sigma = 0.1
# get Confusion Matrix
train$MICHD <- as.factor(train$MICHD)
svm_model <- svm(MICHD ~ ., data = train, cost = 1, sigma = 0.1,kernel = "radial")
# Make predictions on the test set
svm_pred <- predict(svm_model, newdata = test)
accuracy <- sum(svm_pred == test$MICHD) / nrow(test)

# Linear Kernel
SVMlinearGrid <- expand.grid(C = c(0.1, 0.7, 1, 10))
svm_linear <- train(MICHD ~ ., data = train, method = "svmLinear", trControl = ctrl, tuneGrid = SVMlinearGrid, metric = "ROC")
result_linear_MICHD <- data.frame(svm_linear$results)
result_linear_MICHD <- result_linear_MICHD[,1:4]
result_linear_MICHD <- cbind(Model = "SVM - Linear", Outcome = "MICHD", result_linear_MICHD)
result_linear_MICHD
svm_linear$bestTune
svm_pred <- predict(svm_linear, newdata = test)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD))
cm
library(pROC)
svm_pred <- predict(svm_linear, newdata = test, type = "prob")
svm_auc <- roc(factor(test$MICHD), svm_pred[,"X1"])$auc
svm_auc


# Fit the model 
SVMpolyGrid <- expand.grid(C = c(0.1,10), degree = c(2, 3), scale = c(0.01, 0.25))
svm_poly <- train(MICHD ~ ., data = train, method = "svmPoly", trControl = ctrl, 
                  tuneGrid = SVMpolyGrid, metric = "ROC")
result_poly_MICHD <- data.frame(svm_poly$results)
result_poly_MICHD <- result_poly_MICHD[,1:6]
result_poly_MICHD <- cbind(Model = "SVM - Polynomial", Outcome = "MICHD", result_poly_MICHD)
result_poly_MICHD
svm_poly$bestTune # degree = 2, scale = 0.01, C = 0.25
# Predict on test dataset
svm_pred <- predict(svm_poly, newdata = test)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD))
cm
library(pROC)
svm_pred <- predict(svm_poly, newdata = test, type = "prob")
svm_auc <- roc(factor(test$MICHD), svm_pred[,"X1"])$auc
svm_auc
```

## ROC plots

Plain logistic regression
```{r}
library(ggplot2)
library(scales)
# Create data frames with the ROC curve data for each model
roc_pc_df <- data.frame(fpr = roc_log_pc$specificities, tpr = roc_log_pc$sensitivities)
roc_normal_df <- data.frame(fpr = roc_log_normal$specificities, tpr = roc_log_normal$sensitivities)
ggplot() +
  geom_line(data = roc_pc_df, aes(x = fpr, y = tpr, linetype = "Plain Logistic Regression - PCA"), color = "blue", size = 0.6) +
  geom_line(data = roc_normal_df, aes(x = fpr, y = tpr, linetype = "Plain Logistic Regression"), color = "blue", size = 0.6) +
  scale_linetype_manual(name = "Models", values = c("Plain Logistic Regression - PCA" = "dashed", "Plain Logistic Regression" = "solid")) +
  labs(x = "False Positive Rate", y = "True Positive Rate", title = "ROC curves for Plain Logistic Regression") +
  xlim(1,0)+
  theme_classic() +
  theme(legend.position = "bottom")

```

SVM
```{r}
#PCA: Radial - sigma = 0.1, C = 10; Linear - C = 0.7; Polynomial - degree = 3, scale = 0.01, C = 1
#svm_rbf_pca <- svm(as.numeric(factor(MICHD)) ~ ., data = train_pc, kernel = "radial", gamma = 0.1, cost = 10)
#svm_linear_pca <- svm(as.numeric(factor(MICHD)) ~ ., data = train_pc, kernel = "linear", cost = 0.7)
#svm_poly_pca <- svm(as.numeric(factor(MICHD)) ~ ., data = train_pc, kernel = "polynomial",  degree = 3, cost = 1, scale = 0.01)

# Radial - C = 1, sigma = 0.1; 
# Linear - C = 10; 
# Polynomial - degree = 2, scale = 0.01, C = 0.25
svm_rbf_normal <- svm(as.numeric(factor(MICHD)) ~ ., data = train, kernel = "radial", 
                      gamma = 0.1, cost = 1)
svm_linear_normal <- svm(as.numeric(factor(MICHD)) ~ ., data = train, kernel = "linear", cost = 1)
svm_poly_normal <- svm(as.numeric(factor(MICHD)) ~ ., data = train, kernel = "polynomial", 
                       degree = 2, cost = 0.25, scale = 0.01)
svm_rbf_pca <- svm(as.numeric(factor(MICHD)) ~ ., data = train_pc, 
                   kernel = "radial", gamma = 0.1, cost = 1)
svm_linear_pca <- svm(as.numeric(factor(MICHD)) ~ ., data = train_pc, kernel = "linear", cost = 1)
svm_poly_pca <- svm(as.numeric(factor(MICHD))~ ., data = train_pc, 
                    kernel = "polynomial",  degree = 2, cost = 0.25, scale = 0.01)

#######################
log_pred <- predict(fit_michd, newdata = test_pc)
cm <- confusionMatrix(data = log_pred, reference = factor(test_pc$MICHD))
log_pred <- as.numeric(predict(fit_michd, newdata = test_pc))
###########################

# Make predictions on the test set for each SVM model
#test_pc <- predict(preProcess(test, method = c("center", "scale", "pca"))$pca, test)
pred_rbf_pca <- predict(svm_rbf_pca, test_pc)
pred_linear_pca <- predict(svm_linear_pca, test_pc)
pred_poly_pca <- predict(svm_poly_pca, test_pc)
pred_rbf_normal <- predict(svm_rbf_normal, test)
pred_linear_normal <- predict(svm_linear_normal, test)
pred_poly_normal <- predict(svm_poly_normal, test)


# Calculate the ROC curve and AUC for each SVM model
roc_rbf_pca <- roc(test_pc$MICHD, round(pred_rbf_pca))
roc_linear_pca <- roc(test_pc$MICHD, round(pred_linear_pca))
roc_poly_pca <- roc(test_pc$MICHD, round(pred_poly_pca))
roc_rbf_normal <- roc(test$MICHD, round(pred_rbf_normal))
roc_linear_normal <- roc(test$MICHD, round(pred_linear_normal))
roc_poly_normal <- roc(test$MICHD, round(pred_poly_normal))

roc_rbf_pca_df <- data.frame(fpr = roc_rbf_pca$specificities, tpr = roc_rbf_pca$sensitivities)
roc_linear_pca_df <- data.frame(fpr = roc_linear_pca$specificities, 
                                tpr = roc_linear_pca$sensitivities)
roc_poly_pca_df <- data.frame(fpr = roc_poly_pca$specificities, tpr = roc_poly_pca$sensitivities)
roc_rbf_normal_df <- data.frame(fpr = roc_rbf_normal$specificities, 
                                tpr = roc_rbf_normal$sensitivities)
roc_linear_normal_df <- data.frame(fpr = roc_linear_normal$specificities, 
                                   tpr = roc_linear_normal$sensitivities)
roc_poly_normal_df <- data.frame(fpr = roc_poly_normal$specificities, 
                                 tpr = roc_poly_normal$sensitivities)
# Create the combined ROC plot
ggplot() +
  geom_line(data = roc_rbf_normal_df, aes(x = fpr, y = tpr, color = "SVM(RBF)")) +
  geom_line(data = roc_linear_normal_df, aes(x = fpr, y = tpr, color = "SVM(Linear)")) +
  geom_line(data = roc_poly_normal_df, aes(x = fpr, y = tpr, color = "SVM(Polynomial)")) +
  scale_color_manual(name = "Models", 
                     values = c("SVM(RBF)" = "red", 
                                "SVM(Linear)" = "blue", 
                                "SVM(Polynomial)" = "green")) +
  labs(x = "False Positive Rate", y = "True Positive Rate", 
       title = "ROC curves for Support Vector Machine") +
  xlim(1,0) +
  theme_classic() +
  theme(legend.position = "bottom")
```


```{r}
confusionMatrix(data = factor(round(pred_rbf_normal)), reference = factor(as.numeric(test$MICHD)))
pred_linear_normal_new <- round(pred_linear_normal)
pred_linear_normal_new <- ifelse(pred_linear_normal_new <= 1, 1, pred_linear_normal_new)
pred_linear_normal_new <- ifelse(pred_linear_normal_new >= 2, 2, pred_linear_normal_new)
confusionMatrix(data = factor(pred_linear_normal_new), 
                reference = factor(as.numeric(test$MICHD)))
pred_poly_normal_new <- round(pred_poly_normal)
pred_poly_normal_new <- ifelse(pred_poly_normal_new <= 1, 1, pred_poly_normal_new)
pred_poly_normal_new <- ifelse(pred_poly_normal_new >= 2, 2, pred_poly_normal_new)
confusionMatrix(data = factor(pred_poly_normal_new), reference = factor(as.numeric(test$MICHD)))
########### PCA's #############
confusionMatrix(data = factor(round(pred_rbf_pca)), reference = factor(as.numeric(test_pc$MICHD)))
pred_linear_pca_new <- round(pred_linear_pca)
pred_linear_pca_new <- ifelse(pred_linear_pca_new <= 1, 1, pred_linear_pca_new)
pred_linear_pca_new <- ifelse(pred_linear_pca_new >= 2, 2, pred_linear_pca_new)
confusionMatrix(data = factor(pred_linear_pca_new), 
                reference = factor(as.numeric(test$MICHD)))
pred_poly_pca_new <- round(pred_poly_pca)
pred_poly_pca_new <- ifelse(pred_poly_pca_new <= 1, 1, pred_poly_pca_new)
pred_poly_pca_new <- ifelse(pred_poly_pca_new >= 2, 2, pred_poly_pca_new)
confusionMatrix(data = factor(pred_poly_pca_new), reference = factor(as.numeric(test$MICHD)))
```


```{r}
ggplot() +
  geom_line(data = roc_rbf_pca_df, aes(x = fpr, y = tpr, color = "SVM(RBF) - PCA"), linetype = "solid", size = 0.7) +
  geom_line(data = roc_linear_pca_df, aes(x = fpr, y = tpr, color = "SVM(Linear) - PCA"), linetype = "solid", size = 0.7) +
  geom_line(data = roc_poly_pca_df, aes(x = fpr, y = tpr, color = "SVM(Polynomial) - PCA"), linetype = "solid", size = 0.7) +
  geom_line(data = roc_rbf_normal_df, aes(x = fpr, y = tpr, color = "SVM(RBF)"), linetype = "dashed", size = 0.7) +
  geom_line(data = roc_linear_normal_df, aes(x = fpr, y = tpr, color = "SVM(Linear)"), linetype = "dashed", size = 0.7) +
  geom_line(data = roc_poly_normal_df, aes(x = fpr, y = tpr, color = "SVM(Polynomial)"), linetype = "dashed", size = 0.7) +
  scale_color_manual(name = "Models", 
                     values = c("SVM(RBF) - PCA" = "red", 
                                "SVM(Linear) - PCA" = "blue", 
                                "SVM(Polynomial) - PCA" = "green", 
                                "SVM(RBF)" = "red", 
                                "SVM(Linear)" = "blue", 
                                "SVM(Polynomial)" = "green"),
                     guide = guide_legend(override.aes = list(linetype = c("solid", "dashed", "solid","dashed", "solid",   "dashed")))) +
  labs(x = "False Positive Rate", y = "True Positive Rate", 
       title = "ROC curves for Support Vector Machine") +
  xlim(1,0)+
  theme_classic() +
  theme(legend.position = "bottom")

```

## plotting all ROCs together

```{r}
xgboost_pred <- read.csv("final_xgboost_outcomes.csv")
xgboost <- roc(xgboost_pred$xgb_pred, xgboost_pred$test_outcomes)
xgboost_df <- data.frame(fpr = xgboost$specificities, tpr = xgboost$sensitivities)
```
```{r}
library(randomForest)
rf_best <- randomForest(as.factor(MICHD) ~., data = train, 
                        mtry = 11, ntree = 41, nodesize = 10)
pred_rf <- predict(rf_best, newdata = test) 
rf <- roc(test$MICHD, as.numeric(pred_rf))
rf_df <- data.frame(fpr = rf$specificities, tpr = rf$sensitivities)
```
```{r}
########## Ridge ############
lambda_grid <- 10**seq(-4, -1, by=.1)
cv_results <- cv.glmnet(x = model.matrix(MICHD ~ ., data = train), y = train$MICHD, alpha = 0, 
                        family = "binomial", type.measure = "class", lambda = lambda_grid)
best_lambda <- cv_results$lambda.min
ridge <- glmnet(x = model.matrix(MICHD ~ ., data = train),y = train$MICHD,
                alpha = 0, family = "binomial", lambda = best_lambda)
pred_ridge <- predict(ridge, newx = model.matrix(MICHD ~ ., data = test))
pred_ridge <- ifelse(pred_ridge > 0, 1, 0)
ridge <- roc(test$MICHD, as.numeric(pred_ridge))
ridge_df <- data.frame(fpr = ridge$specificities, tpr = ridge$sensitivities)
###### plain logistic regression ######
log_df <- data.frame(fpr = roc_log_normal$specificities, tpr = roc_log_normal$sensitivities)
```
```{r}
######## knn ############
pred_knn <- knn(train = train, test = test, cl = train$MICHD, k = 27)
knn1 <- roc(test$MICHD, as.numeric(pred_knn))
knn1_df <- data.frame(fpr = knn1$specificities, tpr = knn1$sensitivities)
######### knn with PCA #######
dat2 <- dat %>% select(-c("CVDINFR4", "CVDCRHD4", "MICHD"))
dat2 <- sapply(dat2, function (x) as.numeric(x))
pca <- prcomp(dat2, scale.=TRUE)
pca30 <- pca$x[,1:30]
pca30_df <- data.frame(pca30, MICHD=dat$MICHD)
train_index <- createDataPartition(pca30_df$MICHD, p = 0.8, list = FALSE)
train <- pca30_df[train_index, ]
test <- pca30_df[-train_index, ]
pred_knn_pc <- knn(train = train, test = test, cl = train$MICHD, k = 198)
knnpc <- roc(test$MICHD, as.numeric(pred_knn_pc))
knnpc_df <- data.frame(fpr = knnpc$specificities, tpr = knnpc$sensitivities)
```




```{r}
ggplot() +
  geom_line(data = roc_linear_pca_df, aes(x = fpr, y = tpr, color = "SVM(Linear) - PCA"), 
            linetype = "solid", size = 0.7) +
  geom_line(data = roc_linear_normal_df, aes(x = fpr, y = tpr, color = "SVM(Linear)"), 
            linetype = "dashed", size = 0.7) +
  geom_line(data = xgboost_df, aes(x = fpr, y = tpr, color = "XGBoost"), 
            linetype = "solid", size = 0.7) + 
  geom_line(data = rf_df, aes(x = fpr, y = tpr, color = "Random Forest"), 
            linetype = "solid", size = 0.7) + 
  geom_line(data = ridge_df, aes(x = fpr, y = tpr, color = "Penalized Logistic Regression"),
            linetype = "solid", size = 0.7) + 
  geom_line(data = knn1_df, aes(x = fpr, y = tpr, color = "kNN"),
            linetype = "solid", size = 0.7) + 
  geom_line(data = knnpc_df, aes(x = fpr, y = tpr, color = "kNN - PCA"),
            linetype = "dashed", size = 0.7) + 
  scale_color_manual(name = "Models", 
                     values = c("SVM(Linear) - PCA" = "dodgerblue", 
                                "SVM(Linear)" = "dodgerblue", 
                                "XGBoost" = "gold",
                                "Random Forest" = "forestgreen",
                                "Penalized Logistic Regression" = "darkorchid",
                                "kNN" = "firebrick2",
                                "kNN - PCA" = "firebrick2"),
                     guide = guide_legend(override.aes = list(linetype = c("solid","dashed", "solid","solid", "solid","dashed", "solid")))) +
  labs(x = "False Positive Rate", y = "True Positive Rate", 
       title = "ROC curves") +
  xlim(1,0)+
  theme_classic() 
#+ theme(legend.position = "bottom")
```















## DISCARD - SVM with PCA 

```{r}
ctrl <- trainControl(method = "cv", number = 3, summaryFunction = twoClassSummary, 
                     classProbs = TRUE, verboseIter = TRUE)
tuneGrid <- expand.grid(C = c(0.1, 1, 10), sigma = c(0.1, 1, 10))
svm_model <- train(MICHD ~ ., data = train_pc, method = "svmRadial", trControl = ctrl, tuneGrid = tuneGrid, metric = "ROC")
#sigma = 0.1, C = 10
svmlin_pred <- predict(svm_model, newdata = test_pc)
cm <- confusionMatrix(data = svmlin_pred, reference = factor(test_pc$MICHD))
cm
svmlin_pred <- as.numeric(predict(svm_model, newdata = test_pc))
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svmlin_pred)
library(pROC)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
############################ Linear ############################
SVMlinearGrid <- expand.grid(C = c(0.1, 0.7, 1, 10))
svm_linear <- train(MICHD ~ ., data = train_pc, method = "svmLinear", trControl = ctrl, tuneGrid = SVMlinearGrid, metric = "ROC")
result_linear_MICHD <- data.frame(svm_linear$results)
result_linear_MICHD <- result_linear_MICHD[,1:4]
result_linear_MICHD <- cbind(Model = "SVM - Linear", Outcome = "MICHD", result_linear_MICHD)
result_linear_MICHD
svm_linear$bestTune #  C = 0.7
svm_pred <- predict(svm_linear, newdata = test_pc)
cm <- confusionMatrix(data = svm_pred, reference = factor(test_pc$MICHD))
cm
svm_pred <- as.numeric(svm_pred)
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svm_pred)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
############################ Polynomial ############################
svm_poly <- train(MICHD ~ ., data = train_pc, method = "svmPoly", trControl = ctrl, tuneLength = 3, preProcess = c("center","scale"),metric = "ROC")
result_poly_MICHD <- data.frame(svm_poly$results)
result_poly_MICHD <- result_poly_MICHD[,1:6]
result_poly_MICHD <- cbind(Model = "SVM - Polynomial", Outcome = "MICHD", result_poly_MICHD)
result_poly_MICHD
svm_poly$bestTune # degree = 3, scale = 0.01, C = 1
# Predict on test dataset
# Construct the SVM with the best hyperparameters
svm_poly <- svm(as.numeric(factor(train_pc$MICHD)) ~ ., data = train_pc, kernel = "polynomial", 
                degree = 3, gamma = 1/0.01, cost = 1)
predictions <- predict(svm_poly, test_pc)


# Predict using the SVM on the test data
predictions = svm_poly.predict(test_pc)
svm_pred <- predict(svm_poly, newdata = test_pc)
# Calculate accuracy
cm <- confusionMatrix(data = svm_pred, reference = factor(test$MICHD_pc))
cm
svm_pred <- as.numeric(svm_pred)
roc_data <- data.frame(actual = test_pc$MICHD, predicted = svm_pred)
roc <- roc(roc_data$actual, roc_data$predicted)
ggplot(data = data.frame(x = 1 - roc$specificities, y = roc$sensitivities)) +
  geom_line(aes(x = x, y = y)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Receiver Operating Characteristic (ROC) Curve",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)")
```




